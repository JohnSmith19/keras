{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers.core import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 값 설정\n",
    "seed = 0\n",
    "numpy.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.02, 0.0371, 0.0428, ..., 0.0084, 0.009, 0.0032],\n",
       "        [0.0453, 0.0523, 0.0843, ..., 0.0049, 0.0052, 0.0044],\n",
       "        [0.0262, 0.0582, 0.1099, ..., 0.0164, 0.0095, 0.0078],\n",
       "        ...,\n",
       "        [0.0522, 0.0437, 0.018, ..., 0.0138, 0.0077, 0.0031],\n",
       "        [0.0303, 0.0353, 0.049, ..., 0.0079, 0.0036, 0.0048],\n",
       "        [0.026, 0.0363, 0.0136, ..., 0.0036, 0.0061, 0.0115]], dtype=object),\n",
       " array(['R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "        'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "        'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "        'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "        'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "        'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "        'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "        'R', 'R', 'R', 'R', 'R', 'R', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "        'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "        'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "        'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "        'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "        'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "        'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "        'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "        'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "df = pd.read_csv('../../dataset/sonar.csv', header=None)\n",
    "\n",
    "dataset = df.values\n",
    "X = dataset[:, 0:60]\n",
    "Y_obj = dataset[:, 60]\n",
    "X, Y_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label Encoding\n",
    "e = LabelEncoder()\n",
    "e.fit(Y_obj)\n",
    "Y = e.transform(Y_obj)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.0135, 0.0045, 0.0051, ..., 0.0028, 0.003, 0.003],\n",
       "        [0.0293, 0.0644, 0.039, ..., 0.016, 0.0095, 0.0011],\n",
       "        [0.024, 0.0218, 0.0324, ..., 0.0019, 0.0066, 0.0023],\n",
       "        ...,\n",
       "        [0.0228, 0.0106, 0.013, ..., 0.0045, 0.0063, 0.0039],\n",
       "        [0.0373, 0.0281, 0.0232, ..., 0.0054, 0.0085, 0.006],\n",
       "        [0.018, 0.0444, 0.0476, ..., 0.005, 0.0073, 0.0022]], dtype=object),\n",
       " array([[0.0079, 0.0086, 0.0055, ..., 0.0058, 0.0059, 0.0032],\n",
       "        [0.0229, 0.0369, 0.004, ..., 0.0029, 0.0104, 0.0163],\n",
       "        [0.0442, 0.0477, 0.0049, ..., 0.0105, 0.0059, 0.0105],\n",
       "        ...,\n",
       "        [0.0315, 0.0252, 0.0167, ..., 0.0035, 0.0001, 0.0055],\n",
       "        [0.0428, 0.0555, 0.0708, ..., 0.0084, 0.0113, 0.0049],\n",
       "        [0.0239, 0.0189, 0.0466, ..., 0.0026, 0.0036, 0.0024]],\n",
       "       dtype=object),\n",
       " array([1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "        1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "        1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "        0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0]),\n",
       " array([1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "        1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "        1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습셋과 테스트셋의 분리\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=seed)\n",
    "X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/130\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.2522 - acc: 0.5310\n",
      "Epoch 2/130\n",
      "145/145 [==============================] - 0s 311us/step - loss: 0.2463 - acc: 0.5172\n",
      "Epoch 3/130\n",
      "145/145 [==============================] - 0s 329us/step - loss: 0.2440 - acc: 0.5379\n",
      "Epoch 4/130\n",
      "145/145 [==============================] - 0s 346us/step - loss: 0.2414 - acc: 0.5379\n",
      "Epoch 5/130\n",
      "145/145 [==============================] - 0s 297us/step - loss: 0.2399 - acc: 0.5379\n",
      "Epoch 6/130\n",
      "145/145 [==============================] - 0s 321us/step - loss: 0.2374 - acc: 0.5517\n",
      "Epoch 7/130\n",
      "145/145 [==============================] - 0s 292us/step - loss: 0.2342 - acc: 0.5379\n",
      "Epoch 8/130\n",
      "145/145 [==============================] - 0s 340us/step - loss: 0.2303 - acc: 0.5517\n",
      "Epoch 9/130\n",
      "145/145 [==============================] - 0s 327us/step - loss: 0.2176 - acc: 0.6552\n",
      "Epoch 10/130\n",
      "145/145 [==============================] - 0s 304us/step - loss: 0.2065 - acc: 0.7034\n",
      "Epoch 11/130\n",
      "145/145 [==============================] - 0s 306us/step - loss: 0.1991 - acc: 0.7172\n",
      "Epoch 12/130\n",
      "145/145 [==============================] - 0s 344us/step - loss: 0.1965 - acc: 0.7517\n",
      "Epoch 13/130\n",
      "145/145 [==============================] - 0s 327us/step - loss: 0.1850 - acc: 0.7172\n",
      "Epoch 14/130\n",
      "145/145 [==============================] - 0s 421us/step - loss: 0.1751 - acc: 0.7655\n",
      "Epoch 15/130\n",
      "145/145 [==============================] - 0s 361us/step - loss: 0.1698 - acc: 0.7724\n",
      "Epoch 16/130\n",
      "145/145 [==============================] - 0s 327us/step - loss: 0.1645 - acc: 0.7793\n",
      "Epoch 17/130\n",
      "145/145 [==============================] - 0s 345us/step - loss: 0.1601 - acc: 0.7793\n",
      "Epoch 18/130\n",
      "145/145 [==============================] - 0s 345us/step - loss: 0.1558 - acc: 0.7586\n",
      "Epoch 19/130\n",
      "145/145 [==============================] - 0s 358us/step - loss: 0.1538 - acc: 0.7862\n",
      "Epoch 20/130\n",
      "145/145 [==============================] - 0s 318us/step - loss: 0.1492 - acc: 0.7724\n",
      "Epoch 21/130\n",
      "145/145 [==============================] - 0s 337us/step - loss: 0.1497 - acc: 0.8069\n",
      "Epoch 22/130\n",
      "145/145 [==============================] - 0s 358us/step - loss: 0.1442 - acc: 0.8069\n",
      "Epoch 23/130\n",
      "145/145 [==============================] - 0s 351us/step - loss: 0.1438 - acc: 0.7931\n",
      "Epoch 24/130\n",
      "145/145 [==============================] - 0s 304us/step - loss: 0.1370 - acc: 0.8276\n",
      "Epoch 25/130\n",
      "145/145 [==============================] - 0s 416us/step - loss: 0.1361 - acc: 0.8483\n",
      "Epoch 26/130\n",
      "145/145 [==============================] - 0s 364us/step - loss: 0.1358 - acc: 0.8276\n",
      "Epoch 27/130\n",
      "145/145 [==============================] - 0s 355us/step - loss: 0.1318 - acc: 0.8621\n",
      "Epoch 28/130\n",
      "145/145 [==============================] - 0s 353us/step - loss: 0.1353 - acc: 0.8138\n",
      "Epoch 29/130\n",
      "145/145 [==============================] - 0s 342us/step - loss: 0.1288 - acc: 0.8414\n",
      "Epoch 30/130\n",
      "145/145 [==============================] - 0s 338us/step - loss: 0.1359 - acc: 0.8207\n",
      "Epoch 31/130\n",
      "145/145 [==============================] - 0s 341us/step - loss: 0.1275 - acc: 0.8207\n",
      "Epoch 32/130\n",
      "145/145 [==============================] - 0s 342us/step - loss: 0.1268 - acc: 0.8483\n",
      "Epoch 33/130\n",
      "145/145 [==============================] - 0s 430us/step - loss: 0.1217 - acc: 0.8621\n",
      "Epoch 34/130\n",
      "145/145 [==============================] - 0s 339us/step - loss: 0.1214 - acc: 0.8621\n",
      "Epoch 35/130\n",
      "145/145 [==============================] - 0s 360us/step - loss: 0.1208 - acc: 0.8690\n",
      "Epoch 36/130\n",
      "145/145 [==============================] - 0s 354us/step - loss: 0.1228 - acc: 0.8552\n",
      "Epoch 37/130\n",
      "145/145 [==============================] - 0s 351us/step - loss: 0.1222 - acc: 0.8276\n",
      "Epoch 38/130\n",
      "145/145 [==============================] - 0s 313us/step - loss: 0.1126 - acc: 0.8690\n",
      "Epoch 39/130\n",
      "145/145 [==============================] - 0s 407us/step - loss: 0.1148 - acc: 0.8621\n",
      "Epoch 40/130\n",
      "145/145 [==============================] - 0s 354us/step - loss: 0.1119 - acc: 0.8690\n",
      "Epoch 41/130\n",
      "145/145 [==============================] - 0s 301us/step - loss: 0.1118 - acc: 0.8552\n",
      "Epoch 42/130\n",
      "145/145 [==============================] - 0s 398us/step - loss: 0.1094 - acc: 0.8483\n",
      "Epoch 43/130\n",
      "145/145 [==============================] - 0s 355us/step - loss: 0.1092 - acc: 0.8414\n",
      "Epoch 44/130\n",
      "145/145 [==============================] - 0s 425us/step - loss: 0.1074 - acc: 0.8690\n",
      "Epoch 45/130\n",
      "145/145 [==============================] - 0s 462us/step - loss: 0.1078 - acc: 0.8483\n",
      "Epoch 46/130\n",
      "145/145 [==============================] - 0s 348us/step - loss: 0.1088 - acc: 0.8552\n",
      "Epoch 47/130\n",
      "145/145 [==============================] - 0s 371us/step - loss: 0.1062 - acc: 0.8621\n",
      "Epoch 48/130\n",
      "145/145 [==============================] - 0s 337us/step - loss: 0.1024 - acc: 0.8897\n",
      "Epoch 49/130\n",
      "145/145 [==============================] - 0s 310us/step - loss: 0.1037 - acc: 0.8552\n",
      "Epoch 50/130\n",
      "145/145 [==============================] - 0s 360us/step - loss: 0.1059 - acc: 0.8483\n",
      "Epoch 51/130\n",
      "145/145 [==============================] - 0s 350us/step - loss: 0.1010 - acc: 0.8828\n",
      "Epoch 52/130\n",
      "145/145 [==============================] - 0s 346us/step - loss: 0.1033 - acc: 0.8621\n",
      "Epoch 53/130\n",
      "145/145 [==============================] - 0s 301us/step - loss: 0.0964 - acc: 0.8828\n",
      "Epoch 54/130\n",
      "145/145 [==============================] - 0s 315us/step - loss: 0.0966 - acc: 0.8828\n",
      "Epoch 55/130\n",
      "145/145 [==============================] - 0s 359us/step - loss: 0.0959 - acc: 0.8966\n",
      "Epoch 56/130\n",
      "145/145 [==============================] - 0s 326us/step - loss: 0.0954 - acc: 0.8966\n",
      "Epoch 57/130\n",
      "145/145 [==============================] - 0s 340us/step - loss: 0.0929 - acc: 0.8897\n",
      "Epoch 58/130\n",
      "145/145 [==============================] - 0s 339us/step - loss: 0.0910 - acc: 0.8759\n",
      "Epoch 59/130\n",
      "145/145 [==============================] - 0s 349us/step - loss: 0.0939 - acc: 0.8690\n",
      "Epoch 60/130\n",
      "145/145 [==============================] - 0s 484us/step - loss: 0.0903 - acc: 0.8759\n",
      "Epoch 61/130\n",
      "145/145 [==============================] - 0s 358us/step - loss: 0.0871 - acc: 0.8897\n",
      "Epoch 62/130\n",
      "145/145 [==============================] - 0s 286us/step - loss: 0.0877 - acc: 0.8966\n",
      "Epoch 63/130\n",
      "145/145 [==============================] - 0s 292us/step - loss: 0.0944 - acc: 0.8828\n",
      "Epoch 64/130\n",
      "145/145 [==============================] - 0s 358us/step - loss: 0.0904 - acc: 0.8897\n",
      "Epoch 65/130\n",
      "145/145 [==============================] - 0s 303us/step - loss: 0.0897 - acc: 0.8759\n",
      "Epoch 66/130\n",
      "145/145 [==============================] - 0s 290us/step - loss: 0.0876 - acc: 0.8966\n",
      "Epoch 67/130\n",
      "145/145 [==============================] - 0s 307us/step - loss: 0.0827 - acc: 0.9103\n",
      "Epoch 68/130\n",
      "145/145 [==============================] - 0s 319us/step - loss: 0.0834 - acc: 0.8897\n",
      "Epoch 69/130\n",
      "145/145 [==============================] - 0s 294us/step - loss: 0.0807 - acc: 0.9103\n",
      "Epoch 70/130\n",
      "145/145 [==============================] - 0s 367us/step - loss: 0.0803 - acc: 0.9034\n",
      "Epoch 71/130\n",
      "145/145 [==============================] - 0s 258us/step - loss: 0.0776 - acc: 0.9034\n",
      "Epoch 72/130\n",
      "145/145 [==============================] - 0s 377us/step - loss: 0.0822 - acc: 0.8897\n",
      "Epoch 73/130\n",
      "145/145 [==============================] - 0s 290us/step - loss: 0.0764 - acc: 0.9034\n",
      "Epoch 74/130\n",
      "145/145 [==============================] - 0s 261us/step - loss: 0.0800 - acc: 0.8897\n",
      "Epoch 75/130\n",
      "145/145 [==============================] - 0s 326us/step - loss: 0.0761 - acc: 0.8897\n",
      "Epoch 76/130\n",
      "145/145 [==============================] - 0s 422us/step - loss: 0.0764 - acc: 0.9034\n",
      "Epoch 77/130\n",
      "145/145 [==============================] - 0s 334us/step - loss: 0.0730 - acc: 0.9034\n",
      "Epoch 78/130\n",
      "145/145 [==============================] - 0s 336us/step - loss: 0.0722 - acc: 0.9103\n",
      "Epoch 79/130\n",
      "145/145 [==============================] - 0s 363us/step - loss: 0.0706 - acc: 0.9034\n",
      "Epoch 80/130\n",
      "145/145 [==============================] - 0s 266us/step - loss: 0.0701 - acc: 0.9103\n",
      "Epoch 81/130\n",
      "145/145 [==============================] - 0s 358us/step - loss: 0.0701 - acc: 0.9310\n",
      "Epoch 82/130\n",
      "145/145 [==============================] - 0s 341us/step - loss: 0.0658 - acc: 0.9241\n",
      "Epoch 83/130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 0s 348us/step - loss: 0.0672 - acc: 0.9310\n",
      "Epoch 84/130\n",
      "145/145 [==============================] - 0s 280us/step - loss: 0.0634 - acc: 0.9310\n",
      "Epoch 85/130\n",
      "145/145 [==============================] - 0s 341us/step - loss: 0.0627 - acc: 0.9448\n",
      "Epoch 86/130\n",
      "145/145 [==============================] - 0s 298us/step - loss: 0.0628 - acc: 0.9310\n",
      "Epoch 87/130\n",
      "145/145 [==============================] - 0s 334us/step - loss: 0.0607 - acc: 0.9379\n",
      "Epoch 88/130\n",
      "145/145 [==============================] - 0s 325us/step - loss: 0.0602 - acc: 0.9241\n",
      "Epoch 89/130\n",
      "145/145 [==============================] - 0s 305us/step - loss: 0.0571 - acc: 0.9448\n",
      "Epoch 90/130\n",
      "145/145 [==============================] - 0s 295us/step - loss: 0.0574 - acc: 0.9448\n",
      "Epoch 91/130\n",
      "145/145 [==============================] - 0s 303us/step - loss: 0.0632 - acc: 0.9103\n",
      "Epoch 92/130\n",
      "145/145 [==============================] - 0s 293us/step - loss: 0.0546 - acc: 0.9586\n",
      "Epoch 93/130\n",
      "145/145 [==============================] - 0s 343us/step - loss: 0.0542 - acc: 0.9586\n",
      "Epoch 94/130\n",
      "145/145 [==============================] - 0s 317us/step - loss: 0.0523 - acc: 0.9586\n",
      "Epoch 95/130\n",
      "145/145 [==============================] - 0s 318us/step - loss: 0.0519 - acc: 0.9517\n",
      "Epoch 96/130\n",
      "145/145 [==============================] - 0s 277us/step - loss: 0.0512 - acc: 0.9517\n",
      "Epoch 97/130\n",
      "145/145 [==============================] - 0s 298us/step - loss: 0.0473 - acc: 0.9655\n",
      "Epoch 98/130\n",
      "145/145 [==============================] - 0s 308us/step - loss: 0.0462 - acc: 0.9586\n",
      "Epoch 99/130\n",
      "145/145 [==============================] - 0s 304us/step - loss: 0.0450 - acc: 0.9793\n",
      "Epoch 100/130\n",
      "145/145 [==============================] - 0s 305us/step - loss: 0.0469 - acc: 0.9655\n",
      "Epoch 101/130\n",
      "145/145 [==============================] - 0s 289us/step - loss: 0.0494 - acc: 0.9517\n",
      "Epoch 102/130\n",
      "145/145 [==============================] - 0s 261us/step - loss: 0.0465 - acc: 0.9586\n",
      "Epoch 103/130\n",
      "145/145 [==============================] - 0s 277us/step - loss: 0.0449 - acc: 0.9586\n",
      "Epoch 104/130\n",
      "145/145 [==============================] - 0s 273us/step - loss: 0.0455 - acc: 0.9586\n",
      "Epoch 105/130\n",
      "145/145 [==============================] - 0s 362us/step - loss: 0.0418 - acc: 0.9586\n",
      "Epoch 106/130\n",
      "145/145 [==============================] - 0s 320us/step - loss: 0.0456 - acc: 0.9586\n",
      "Epoch 107/130\n",
      "145/145 [==============================] - 0s 304us/step - loss: 0.0390 - acc: 0.9655\n",
      "Epoch 108/130\n",
      "145/145 [==============================] - 0s 306us/step - loss: 0.0385 - acc: 0.9862\n",
      "Epoch 109/130\n",
      "145/145 [==============================] - 0s 259us/step - loss: 0.0452 - acc: 0.9379\n",
      "Epoch 110/130\n",
      "145/145 [==============================] - 0s 303us/step - loss: 0.0405 - acc: 0.9586\n",
      "Epoch 111/130\n",
      "145/145 [==============================] - 0s 325us/step - loss: 0.0362 - acc: 0.9724\n",
      "Epoch 112/130\n",
      "145/145 [==============================] - 0s 288us/step - loss: 0.0351 - acc: 0.9931\n",
      "Epoch 113/130\n",
      "145/145 [==============================] - 0s 250us/step - loss: 0.0361 - acc: 0.9724\n",
      "Epoch 114/130\n",
      "145/145 [==============================] - 0s 276us/step - loss: 0.0355 - acc: 0.9862\n",
      "Epoch 115/130\n",
      "145/145 [==============================] - 0s 338us/step - loss: 0.0332 - acc: 0.9931\n",
      "Epoch 116/130\n",
      "145/145 [==============================] - 0s 275us/step - loss: 0.0343 - acc: 0.9862\n",
      "Epoch 117/130\n",
      "145/145 [==============================] - 0s 304us/step - loss: 0.0308 - acc: 0.9862\n",
      "Epoch 118/130\n",
      "145/145 [==============================] - 0s 325us/step - loss: 0.0299 - acc: 0.9862\n",
      "Epoch 119/130\n",
      "145/145 [==============================] - 0s 280us/step - loss: 0.0308 - acc: 0.9931\n",
      "Epoch 120/130\n",
      "145/145 [==============================] - 0s 300us/step - loss: 0.0289 - acc: 0.9931\n",
      "Epoch 121/130\n",
      "145/145 [==============================] - 0s 386us/step - loss: 0.0302 - acc: 0.9931\n",
      "Epoch 122/130\n",
      "145/145 [==============================] - 0s 367us/step - loss: 0.0291 - acc: 0.9931\n",
      "Epoch 123/130\n",
      "145/145 [==============================] - 0s 358us/step - loss: 0.0279 - acc: 0.9862\n",
      "Epoch 124/130\n",
      "145/145 [==============================] - 0s 397us/step - loss: 0.0284 - acc: 0.9931\n",
      "Epoch 125/130\n",
      "145/145 [==============================] - 0s 504us/step - loss: 0.0270 - acc: 0.9931\n",
      "Epoch 126/130\n",
      "145/145 [==============================] - 0s 278us/step - loss: 0.0274 - acc: 0.9931\n",
      "Epoch 127/130\n",
      "145/145 [==============================] - 0s 237us/step - loss: 0.0268 - acc: 0.9931\n",
      "Epoch 128/130\n",
      "145/145 [==============================] - 0s 316us/step - loss: 0.0267 - acc: 0.9931\n",
      "Epoch 129/130\n",
      "145/145 [==============================] - 0s 222us/step - loss: 0.0247 - acc: 0.9931\n",
      "Epoch 130/130\n",
      "145/145 [==============================] - 0s 210us/step - loss: 0.0226 - acc: 0.9931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa38021d4e0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim=60, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, epochs=130, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 디스크에 저장\n",
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트를 위해 메모르의 모델을 삭제하고 디스크에서 로드한다.\n",
    "del model\n",
    "model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n",
      "Test Accuracy: 0.8095\n"
     ]
    }
   ],
   "source": [
    "print('Test Accuracy: %.4f' % (model.evaluate(X_test, Y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디스크의 모델을 삭제한다.\n",
    "os.remove('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
