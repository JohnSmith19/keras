{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2, 4, 6, 8, 10, 12, 14], [0, 0, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x, y의 데이터 값\n",
    "# x,y의 데이터 값\n",
    "data = [[2, 0], [4, 0], [6, 0], [8, 1], [10, 1], [12, 1], [14, 1]]\n",
    "x_data = [x_row[0] for x_row in data]\n",
    "y_data = [y_row[1] for y_row in data]\n",
    "\n",
    "x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a와 b 값을 임의로 정한다.\n",
    "a = tf.Variable(tf.random_normal([1], dtype=tf.float64, seed=0))\n",
    "b = tf.Variable(tf.random_normal([1], dtype=tf.float64, seed=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y 시그모이드 함수의 방정식을 세운다.\n",
    "y = 1/(1 + np.e**(a * x_data + b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss 를 구하는 함수\n",
    "loss = -tf.reduce_mean(np.array(y_data) * tf.log(y) + (1 - np.array(y_data)) * tf.log(1 - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습률\n",
    "learning_rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss 를 최소화 하는 값 찾기\n",
    "gradient_decent = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss = 1.2676, a = 0.1849, y = -0.4334\n",
      "Epoch: 6000, loss = 0.0152, a = -2.9211, y = 20.2982\n",
      "Epoch: 12000, loss = 0.0081, a = -3.5637, y = 24.8010\n",
      "Epoch: 18000, loss = 0.0055, a = -3.9557, y = 27.5463\n",
      "Epoch: 24000, loss = 0.0041, a = -4.2380, y = 29.5231\n",
      "Epoch: 30000, loss = 0.0033, a = -4.4586, y = 31.0675\n",
      "Epoch: 36000, loss = 0.0028, a = -4.6396, y = 32.3346\n",
      "Epoch: 42000, loss = 0.0024, a = -4.7930, y = 33.4086\n",
      "Epoch: 48000, loss = 0.0021, a = -4.9261, y = 34.3406\n",
      "Epoch: 54000, loss = 0.0019, a = -5.0436, y = 35.1636\n",
      "Epoch: 60000, loss = 0.0017, a = -5.1489, y = 35.9005\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(60001):\n",
    "        sess.run(gradient_decent)\n",
    "        if i % 6000 == 0:\n",
    "            print(\"Epoch: %.f, loss = %.4f, a = %.4f, y = %.4f\" % (i, sess.run(loss), sess.run(a), sess.run(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
